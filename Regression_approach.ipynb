{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNyw6wb0oZJEU1OEETWPVbK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mortgad/DLVR/blob/main/Regression_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to google"
      ],
      "metadata": {
        "id": "RnYoRU6-Gs2q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4J-aVlMGpOx",
        "outputId": "7f65483b-b824-4ee2-cd7f-f6ae5f85cbd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# save_model_path = '/content/drive/MyDrive/DL for VR/Project/Models' # Thomas\n",
        "# save_model_path = '/content/drive/MyDrive/Deep_Learning_Visual_Recognition/Project/' # Morten\n",
        "save_model_path = '/content/drive/MyDrive/Visual reg' # Mads\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mortgad/DLVR.git\n",
        "%cd DLVR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7ZWhGRRLVTP",
        "outputId": "14120fce-819c-45ed-ab04-d090232ac609"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DLVR'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Counting objects: 100% (198/198), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 340 (delta 118), reused 163 (delta 95), pack-reused 142 (from 1)\u001b[K\n",
            "Receiving objects: 100% (340/340), 16.85 MiB | 37.43 MiB/s, done.\n",
            "Resolving deltas: 100% (180/180), done.\n",
            "/content/DLVR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.utkface import load_utkface\n",
        "load_utkface()\n",
        "\n",
        "from utils.utkface import preprocess_utkface\n",
        "df_utkface, df_utkface_raw = preprocess_utkface()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAhq3hkgSJYG",
        "outputId": "f3c08e25-6218-45c3-f44b-c7717c451524"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading part3.tar.gz\n",
            "Extracted part3.tar.gz\n",
            "Downloading part2.tar.gz\n",
            "Extracted part2.tar.gz\n",
            "Downloading part1.tar.gz\n",
            "Extracted part1.tar.gz\n",
            "Deleted: /content/extracted/part3/44_1_4_20170116235150272.pg\n",
            "Deleted: /content/extracted/part3/55_0_0_20170116232725357jpg\n",
            "Deleted: /content/extracted/part3/.DS_Store\n",
            "Deleted: /content/extracted/part1/61_1_20170109142408075.jpg\n",
            "Deleted: /content/extracted/part1/61_3_20170109150557335.jpg\n",
            "Deleted: /content/extracted/part2/53__0_20170116184028385.jpg\n",
            "Deleted: /content/extracted/part2/39_1_20170116174525125.jpg\n",
            "Deleted: /content/extracted/part3/24_0_1_20170116220224657 .jpg\n",
            "Processing from: /content/extracted/part1\n",
            "Processing from: /content/extracted/part2\n",
            "Processing from: /content/extracted/part3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get data for modelling\n"
      ],
      "metadata": {
        "id": "PwVBD43AOUI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop not needed colums:\n",
        "df = df_utkface_raw[['age_raw','gender','race','file']]\n",
        "\n",
        "df = df[df['age_raw']<=100]\n",
        "\n",
        "df.rename(columns={'age_raw': 'age_code'}, inplace=True)\n",
        "df.rename(columns={'gender': 'gender_code'}, inplace=True)\n",
        "df.rename(columns={'race': 'race_code'}, inplace=True)"
      ],
      "metadata": {
        "id": "OK1DoDT4Pe6G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.preprocessing import create_lists\n",
        "\n",
        "images, ages, races, genders = create_lists(df)\n",
        "print(f\"Loaded {len(images)} images.\")\n",
        "\n",
        "# Number of classes for target variable\n",
        "num_classes_age = len(set(ages))\n",
        "num_classes_gender = len(set(genders))\n",
        "num_classes_ethnicity = len(set(races))\n",
        "print(f\"Number of age classes: {num_classes_age}\")\n",
        "print(f\"Number of gender classes: {num_classes_gender}\")\n",
        "print(f\"Number of ethnicity classes: {num_classes_ethnicity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIsnadTuUX-V",
        "outputId": "31e0498f-a86a-4cff-eeb1-c2bc7d8bfb8e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 24079 images.\n",
            "Number of age classes: 97\n",
            "Number of gender classes: 2\n",
            "Number of ethnicity classes: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications.resnet_v2 import preprocess_input\n",
        "\n",
        "images_preprocessed = preprocess_input(images)\n",
        "\n",
        "# Split into train (80%) and temp (20%)\n",
        "X_train, X_temp, y_train_age, y_temp_age, y_train_races, y_temp_races, y_train_gender, y_temp_gender = train_test_split(images_preprocessed, ages, races, genders, test_size=0.20, random_state=42, stratify=ages)\n",
        "\n",
        "# Split temp into validation (75% of temp, which is 15% of original data) and test (25% of temp, which is 5% of original data)\n",
        "X_val, X_test, y_val_age, y_test_age, y_val_races, y_test_races, y_val_gender, y_test_gender = train_test_split(X_temp, y_temp_age, y_temp_races, y_temp_gender, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, Training labels: {y_train_age.shape}\")\n",
        "print(f\"Age validation set: {X_val.shape}, Age validation labels: {y_val_age.shape}\")\n",
        "print(f\"Age test set: {X_test.shape}, Age test labels: {y_test_age.shape}\")\n",
        "print(f\"Race validation labels: {y_val_races.shape}\")\n",
        "print(f\"Race test labels: {y_test_races.shape}\")\n",
        "print(f\"Gender validation labels: {y_val_gender.shape}\")\n",
        "print(f\"Gender test labels: {y_test_gender.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68HdoN4EbBF8",
        "outputId": "9e5b2b69-7cfb-4d8a-894e-b23fd40c6ae9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (19263, 224, 224, 3), Training labels: (19263,)\n",
            "Age validation set: (3612, 224, 224, 3), Age validation labels: (3612,)\n",
            "Age test set: (1204, 224, 224, 3), Age test labels: (1204,)\n",
            "Race validation labels: (3612,)\n",
            "Race test labels: (1204,)\n",
            "Gender validation labels: (3612,)\n",
            "Gender test labels: (1204,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training model"
      ],
      "metadata": {
        "id": "0Sicag_zde-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow import keras\n",
        "\n",
        "# Now proceed with the ResNet50V2 model using the preprocessed images\n",
        "conv_base = ResNet50V2(\n",
        "    include_top=False,  # Exclude the top fully connected layers\n",
        "    weights=\"imagenet\",  # Load pre-trained ImageNet weights\n",
        "    input_shape=(images_preprocessed[0].shape[0], images_preprocessed[0].shape[1], images_preprocessed[0].shape[2]),  # Input shape from the preprocessed images\n",
        ")\n",
        "\n",
        "conv_base.trainable = False  # Freeze the pre-trained layers\n",
        "\n",
        "print(\"Conv base, training, and validation sets have been created...\")\n",
        "\n",
        "# Create the new model using ResNet50V2 as the base\n",
        "inputs = keras.Input(shape=(images_preprocessed[0].shape[0], images_preprocessed[0].shape[1], images_preprocessed[0].shape[2]))\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "x = conv_base(inputs)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.3)(x)  # Dropout with a 50% rate\n",
        "\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.2)(x)  # Dropout with a 40% rate\n",
        "\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "\n",
        "# Adjust the output layer for age prediction\n",
        "outputs = layers.Dense(1, activation='linear')(x)  # Single neuron for numeric output\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIMfCrOIdgn2",
        "outputId": "60b67b1c-b6b2-4ae6-f7e3-ab25ca6b09a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 0s 0us/step\n",
            "Conv base, training, and validation sets have been created...\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " resnet50v2 (Functional)     (None, 7, 7, 2048)        23564800  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 2048)              8192      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24798209 (94.60 MB)\n",
            "Trainable params: 1227521 (4.68 MB)\n",
            "Non-trainable params: 23570688 (89.92 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1.5e-4)\n",
        "model.compile(loss=\"mean_squared_error\",  # Use MSE or MAE for regression\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])  # Optionally use MAE as a metric\n",
        "\n",
        "# Define the callback for saving the best model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "file_path = '/content/drive/MyDrive/Visual reg' + \"/\"\n",
        "model_name = 'resnet50v2_model_baseline.keras'\n",
        "\n",
        "# Save the model in the new Keras format with the best validation accuracy\n",
        "checkpoint = ModelCheckpoint(file_path + model_name,\n",
        "                             monitor='val_mae',  # Monitor MAE for regression\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='min')  # For MAE, lower is better\n",
        "\n",
        "# Train the model\n",
        "resnet_history = model.fit(\n",
        "    X_train,\n",
        "    y_train_age,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val_age),\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jh0LB1Pdhas",
        "outputId": "4c210819-150c-47d2-d49c-ac1537383366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "602/602 [==============================] - ETA: 0s - loss: 686.0565 - mae: 20.6587\n",
            "Epoch 1: val_mae improved from inf to 12.23808, saving model to /content/drive/MyDrive/Visual reg/resnet50v2_model_baseline.keras\n",
            "602/602 [==============================] - 286s 469ms/step - loss: 686.0565 - mae: 20.6587 - val_loss: 242.5660 - val_mae: 12.2381\n",
            "Epoch 2/20\n",
            "509/602 [========================>.....] - ETA: 36s - loss: 197.4240 - mae: 10.7164"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.preprocessing import evaluate_and_plot\n",
        "\n",
        "# Evaluate and plot the model\n",
        "evaluate_and_plot(resnet_history)"
      ],
      "metadata": {
        "id": "ZU74AK6qdlz4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}